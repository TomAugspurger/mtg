{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "\n",
    "[Pandas](http://pandas.pydata.org) and [scikit-learn](http://scikit-learn.org/stable/) have largely overlapping, but different data models.\n",
    "Both are based off NumPy arrays, but the extensions pandas has made to NumPy's type system have created a slight rift between the two. Most notably, pandas supports heterogenous data and has added several extension data-types on top of NumPy.\n",
    "\n",
    "### 1. Homogeneity vs. Heterogeneity\n",
    "\n",
    "NumPy `ndarray`s (and so scikit-learn feature matrices) are *homogeneous*, they must have a single dtype, regardless of the number of dimensions.\n",
    "Pandas `DataFrame`s are potentially *heterogenous*, and can store columns of multiple dtypes within a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array([\n",
    "    [10, 1.0],  # mix of integer and floats\n",
    "    [20, 2.0],\n",
    "    [30, 3.0],\n",
    "    ])\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\n",
    "    [10, 1.0],\n",
    "    [20, 2.0],\n",
    "    [30, 3.0]\n",
    "])\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extension Types\n",
    "\n",
    "Pandas has implemented some *extension dtypes*: `Categoricals` and datetimes with timezones.\n",
    "In statistics, categorical data refers to a variable that can take only a limited, fixed set of distince values (e.g. days of week).\n",
    "These extension types cannot be expressed natively as NumPy arrays, and must go through some kind of (potentially lossy) conversion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = pd.Series(pd.Categorical(['a', 'b', 'c', 'a'],\n",
    "                             categories=['d', 'a', 'b', 'c'],\n",
    "                             ordered=True))\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Casting this to a NumPy array loses the categories and ordered information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.asarray(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"Real-world\" data is often complex and heterogeneous, making pandas the tool of choice.\n",
    "However, tools like Scikit-Learn, which do not depend on pandas, can't use its\n",
    "richer data structures.\n",
    "We need a way of bridging the gap between pandas' DataFrames and the NumPy arrays appropriate for scikit-learn.\n",
    "Fortunately the tools are all there to make this conversion smooth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "For our example we'll work with a simple dataset on tips:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tips.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target variable is the tip amount. The remainder of the columns make up our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df['tip']\n",
    "X = df.drop('tip', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the feature matrix is a mixture of numeric and categorical (in the statistical sense) columns. The categorical columns are just stored as python `object`s; we'll fix that later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Stats\n",
    "\n",
    "We'll use a linear regression to predict `tip`.\n",
    "When you fit a linear regression, you end up having to solve an equation like\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{\\beta}} = \\left(\\boldsymbol{X}^T\\boldsymbol{X}\\right)^{-1} \\boldsymbol{X}^T \\boldsymbol{y}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "- $\\hat{\\boldsymbol{\\beta}}$ is our estimate for the vector of coefficients describing the best-fit line\n",
    "- $\\boldsymbol{X}$ is the feature matrix\n",
    "- $\\boldsymbol{y}$ is the target array (tip amount)\n",
    "\n",
    "There's no need to worry about that equation; it likely won't make sense unless you've seen it before.\n",
    "The only point I want to emphasize is that finding the optimal set of coefficients requires doing a matrix multiplication.\n",
    "This means we (or our library) needs to somehow convert our *categorical* data (`sex`, `smoker`, `day`, and `time`) into numeric data.\n",
    "The next two sections offer some possible ways of doing that conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorize\n",
    "\n",
    "One option [often suggested](http://stackoverflow.com/q/25530504/1889400) is to *factorize* the non-numeric columns.\n",
    "Factorization maps each distinct field to numeric codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "codes, labels = pd.factorize(df['day'])\n",
    "print('Codes:  ', codes[::10], end='\\n\\n')\n",
    "print('Labels: ', labels[codes[::10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So every occurance of `'Sun'` becomes `0`, each `'Sat'` becomes `1`, and so on.\n",
    "\n",
    "We could assign the factorized values into a new DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_cols = ['sex', 'smoker', 'day', 'time']\n",
    "\n",
    "X_factorized = X.copy()\n",
    "X_factorized[cat_cols] = X_factorized[cat_cols].apply(\n",
    "    lambda x: pd.factorize(x)[0]\n",
    ")\n",
    "X_factorized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And fit the regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_factorized, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Series(lm.coef_, X_factorized.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We successfully fit the model.\n",
    "However, there are several problems with this approach.\n",
    "\n",
    "First, ordering of the unique values *before* factorization becomes important.\n",
    "If we wanted to predict for a related dataset using the same model, we would need\n",
    "to ensure that the original values get factorized to the same numerical values.\n",
    "If the order differed, say `sex='male'` came first instead of `sex='female'`, values for `'male'` would be factorized to `0` instead of `1`, and our predictions would be incorrect.\n",
    "We would like for our data container to store the relationship between category and numeric code for us.\n",
    "\n",
    "Second it asserts that the difference between any two \"adjacent\" categories is the same.\n",
    "In our linear model, this implies that the change in $tip$ with respect to a jump from `'Sunday'` to `'Saturday'` has the same effect as a jump from `'Saturday'` to `'Thursday'`.\n",
    "\n",
    "$$\n",
    "\\frac{\n",
    "  \\Delta{\\text{tip}}\n",
    "}{\n",
    "  \\Delta({\\text{Sun.} \\rightarrow \\text{Sat.}})\n",
    "} = \\frac{\n",
    "  \\Delta{\\text{tip}}\n",
    "}{\n",
    "  \\Delta({\\text{Sat.} \\rightarrow \\text{Thur.}})\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot what this looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style='ticks', context='talk')\n",
    "\n",
    "# Fit just \"tip ~ day\", to make plotting easier\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_factorized[['day']], y)\n",
    "b0, b1 = lm.intercept_, lm.coef_.ravel()[0]\n",
    "\n",
    "ax = sns.stripplot('day', 'tip', data=df, jitter=1)\n",
    "xlim = ax.get_xlim()\n",
    "xx = np.linspace(*xlim, 2)\n",
    "ax.plot(xx, [3.2245 + b1 * xx[0], b0 + b1 * xx[1]], lw=4)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may not be true in practice, and our data representation should not force our model to assume it.\n",
    "Better to let the model *discover* that relationship, if it actually happens to be there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Encoding\n",
    "\n",
    "There's a better approach, dummy encoding.\n",
    "This expands each categorical column to *multiple* columns, one per distinct value.\n",
    "The values in these new dummy-encoded columns are either 1, indicating the presence of that value in that observation, or 0.\n",
    "Versions of this are implemented in both scikit-learn and pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "enc = LabelBinarizer()\n",
    "enc.fit_transform(df['day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the `day` column has expanded to four, one for each unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.day.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I recommend the pandas version, `get_dummies`. It offers a few conveniences:\n",
    "\n",
    "- Operates on multiple columns at once\n",
    "- Passes through numeric columns unchanged\n",
    "- Preserves row and column labels\n",
    "- Provides a `drop_first` keyword for dropping a level per column. You might want this to avoid [perfect multicolinearity](https://en.wikipedia.org/wiki/Multicollinearity) if you have an intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_dummy, y)\n",
    "\n",
    "pd.Series(lm.coef_, index=X_dummy.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version solves both of our issues with `factorize`.\n",
    "\n",
    "1. The ordering of rows doesn't matter anymore because the dummy-columns are computed on the sorted version of the categories\n",
    "2. \"adjacent\" categories each have their own parameter, so they're free to have their own effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refinements\n",
    "\n",
    "Our last approach worked, but there's still room for improvement.\n",
    "\n",
    "1. We can't easily go from dummies back to categoricals\n",
    "2. Doesn't integrate with scikit-learn `Pipeline` objects.\n",
    "3. If working with a larger dataset and `partial_fit`, codes could be missing from subsets of the data.\n",
    "4. Memory inefficient if there are many records relative to distinct categories\n",
    "\n",
    "To solve these, we'll store additonal information in the *type* of the column and write a [Transformer](http://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html) to handle the conversion to and from dummies.\n",
    "\n",
    "Pandas provides a `Categorical` dtype, which stores\n",
    "\n",
    "- All the possible values the column can take\n",
    "- Whether there is an ordering on the categories\n",
    "- A relationship between each distinct categorical value and an integer code\n",
    "\n",
    "Let's convert the categorical columns to `Categorical` dtype.\n",
    "With `.astype('category')` we're just using the defaults of\n",
    "\n",
    "- The set of categories is just the set present in the column\n",
    "- There is no ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = ['sex', 'smoker', 'day', 'time']\n",
    "df[columns] = df[columns].apply(lambda x: x.astype('category'))\n",
    "\n",
    "y = df['tip']\n",
    "X = df.drop('tip', axis=1)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Transformer\n",
    "\n",
    "We now have the pieces in place to solve all our issues.\n",
    "We'll write a class for use in a scikit-learn `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class CategoricalTransformer(TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.columns_ = X.columns\n",
    "        self.cat_cols_ = X.select_dtypes(include=['category']).columns\n",
    "        self.non_cat_cols_ = X.columns.drop(self.cat_cols_)\n",
    "        self.cat_map_ = {col: X[col].cat for col in self.cat_cols_}\n",
    "        \n",
    "        self.cat_blocks_ = {}  # {cat col: slice}\n",
    "        left = len(self.non_cat_cols_)\n",
    "        for col in self.cat_cols_:\n",
    "            right = left + len(self.cat_map_[col].categories)\n",
    "            self.cat_blocks_[col] = slice(left, right)\n",
    "            left = right\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return np.asarray(pd.get_dummies(X))\n",
    "    \n",
    "    def inverse_transform(self, trn, y=None):\n",
    "        numeric = pd.DataFrame(trn[:, :len(self.non_cat_cols_)],\n",
    "                               columns=self.non_cat_cols_)\n",
    "        series = []\n",
    "        for col, slice_ in self.cat_blocks_.items():\n",
    "            codes = trn[:, slice_].argmax(1)\n",
    "            cat = self.cat_map_[col]\n",
    "            cat = pd.Categorical.from_codes(codes,\n",
    "                                            cat.categories,\n",
    "                                            cat.ordered)\n",
    "            series.append(pd.Series(cat, name=col))\n",
    "        return pd.concat([numeric] + series, axis='columns')[self.columns_]\n",
    "\n",
    "ct = CategoricalTransformer()\n",
    "trn = ct.fit_transform(X)\n",
    "trn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
